name: Build and Deploy to EC2

on:
  push:
    branches: [ main ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  workflow_dispatch:

jobs:
  lint:
    name: Lint Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: 'frontend/package-lock.json'
        
    - name: Lint Frontend
      run: |
        cd frontend
        npm ci
        npm run lint
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.24'
    
    - name: Lint Backend (Go)
      uses: golangci/golangci-lint-action@v3
      with:
        version: latest
        working-directory: ./backend
        args: --timeout=5m

  build-and-push:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    needs: lint
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-southeast-1
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
      
    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-
      
    - name: Build and push frontend image
      uses: docker/build-push-action@v4
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: true
        tags: |
          ${{ steps.login-ecr.outputs.registry }}/getstok-frontend:${{ github.sha }}
          ${{ steps.login-ecr.outputs.registry }}/getstok-frontend:latest
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
        
    - name: Build and push backend image
      uses: docker/build-push-action@v4
      with:
        context: ./backend
        file: ./backend/Dockerfile
        push: true
        tags: |
          ${{ steps.login-ecr.outputs.registry }}/getstok-backend:${{ github.sha }}
          ${{ steps.login-ecr.outputs.registry }}/getstok-backend:latest
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
        
    - name: Build and push notification service image
      uses: docker/build-push-action@v4
      with:
        context: ./notification_service
        file: ./notification_service/Dockerfile
        push: true
        tags: |
          ${{ steps.login-ecr.outputs.registry }}/getstok-notification:${{ github.sha }}
          ${{ steps.login-ecr.outputs.registry }}/getstok-notification:latest
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
        
    - name: Build and push MQTT broker image
      uses: docker/build-push-action@v4
      with:
        context: ./mqtt_broker
        file: ./mqtt_broker/Dockerfile
        push: true
        tags: |
          ${{ steps.login-ecr.outputs.registry }}/getstok-mqtt:${{ github.sha }}
          ${{ steps.login-ecr.outputs.registry }}/getstok-mqtt:latest
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
        
    # Prevent cache from growing too large
    - name: Move cache
      run: |
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  deploy:
    name: Deploy to EC2
    runs-on: ubuntu-latest
    needs: build-and-push
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-southeast-1
        
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
      
    - name: Generate docker-compose.prod.yml
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cat > docker-compose.prod.yml << EOL
        # Docker Compose file untuk produksi (otomatis generated by GitHub Actions)
        name: getstok-fleet-monitoring

        services:
          # Frontend service
          frontend:
            image: ${ECR_REGISTRY}/getstok-frontend:${IMAGE_TAG}
            container_name: getstok-frontend
            restart: unless-stopped
            ports:
              - "3000:3000"
            env_file:
              - ./frontend/.env
            networks:
              - getstok-network
            depends_on:
              - backend
              - notification-service
            environment:
              - NODE_ENV=production

          # Backend service dengan PostgreSQL
          postgres:
            image: postgres:16-alpine
            container_name: getstok_postgres
            ports:
              - "5433:5432"
            env_file:
              - ./backend/.env.db
            volumes:
              - postgres_data:/var/lib/postgresql/data
            restart: always
            networks:
              - getstok-network
            healthcheck:
              test: ["CMD-SHELL", "pg_isready -U ybandung"]
              interval: 5s
              timeout: 5s
              retries: 5

          backend:
            image: ${ECR_REGISTRY}/getstok-backend:${IMAGE_TAG}
            container_name: getstok_api
            restart: unless-stopped
            ports:
              - "8080:8080"
            env_file:
              - ./backend/.env
            environment:
              - MQTT_BROKER_URL=tcp://getstok-mqtt:1883
            depends_on:
              postgres:
                condition: service_healthy
              mqtt-broker:
                condition: service_started
            networks:
              - getstok-network

          # Notification service
          notification-service:
            image: ${ECR_REGISTRY}/getstok-notification:${IMAGE_TAG}
            container_name: getstok-notification
            restart: unless-stopped
            ports:
              - "8081:8081"
            env_file:
              - ./notification_service/.env
            environment:
              - DB_HOST=postgres
            depends_on:
              postgres:
                condition: service_healthy
            networks:
              - getstok-network

          # MQTT Broker service
          mqtt-broker:
            image: ${ECR_REGISTRY}/getstok-mqtt:${IMAGE_TAG}
            container_name: getstok-mqtt
            restart: unless-stopped
            ports:
              - "1883:1883"  # MQTT default port
              - "9001:9001"  # WebSockets port
            networks:
              - getstok-network

        networks:
          getstok-network:
            driver: bridge

        volumes:
          postgres_data:
            driver: local
        EOL
        
    - name: Copy docker-compose.prod.yml to EC2
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/ec2.pem
        chmod 600 ~/.ssh/ec2.pem
        
        scp -o StrictHostKeyChecking=no -i ~/.ssh/ec2.pem docker-compose.prod.yml ec2-user@${{ secrets.EC2_HOST }}:~/GetstokFleetMonitoring/
        
    - name: Deploy to EC2
      run: |
        ssh \
          -o ServerAliveInterval=60 \
          -o ServerAliveCountMax=60 \
          -o StrictHostKeyChecking=no \
          -i ~/.ssh/ec2.pem \
          ec2-user@${{ secrets.EC2_HOST }} '
          # Log directory
          mkdir -p ~/deploy-logs
          
          # Log file
          LOG_FILE=~/deploy-logs/deploy-$(date +%Y-%m-%d-%H-%M-%S).log
          
          # Start logging
          {
            echo "=== Deployment started at $(date) ==="
            
            # Navigate to project directory
            cd ~/GetstokFleetMonitoring
            
            # Pull latest changes
            echo "Pulling latest changes..."
            git pull origin main
            
            # Ensure all .env files exist
            if [ -f backend/.env.example ] && [ ! -f backend/.env ]; then
              echo "Creating backend/.env from backend/.env.example"
              cp backend/.env.example backend/.env
            fi
            
            if [ -f backend/.env.db.example ] && [ ! -f backend/.env.db ]; then
              echo "Creating backend/.env.db from backend/.env.db.example"
              cp backend/.env.db.example backend/.env.db
            fi
            
            if [ -f notification_service/.env.example ] && [ ! -f notification_service/.env ]; then
              echo "Creating notification_service/.env from notification_service/.env.example"
              cp notification_service/.env.example notification_service/.env
            fi
            
            if [ -f frontend/.env.example ] && [ ! -f frontend/.env ]; then
              echo "Creating frontend/.env from frontend/.env.example"
              cp frontend/.env.example frontend/.env
            fi
            
            # Make sure required directories for mqtt broker exist
            echo "Checking and creating MQTT broker directories if needed..."
            mkdir -p mqtt_broker/mqtt/data mqtt_broker/mqtt/log
            chmod -R 777 mqtt_broker/mqtt/data mqtt_broker/mqtt/log
            
            # Login to ECR
            echo "Logging in to Amazon ECR..."
            aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.ap-southeast-1.amazonaws.com
            
            # Stop existing containers
            echo "Stopping existing containers..."
            if [ -f docker-compose.yml ]; then
              docker-compose down
            fi
            
            # Pull and start with new images
            echo "Pulling and starting containers using production configuration..."
            docker-compose -f docker-compose.prod.yml pull
            docker-compose -f docker-compose.prod.yml up -d
            
            # Display status
            echo "Container status:"
            docker-compose -f docker-compose.prod.yml ps
            
            # Clean up unused Docker resources
            echo "Cleaning up unused Docker resources..."
            docker image prune -f
            
            # Cleanup old logs
            echo "Cleaning up old deployment logs..."
            cd ~/deploy-logs
            ls -t | tail -n +11 | xargs -r rm
            
            # Check disk space
            echo "Disk usage after deployment:"
            df -h /
            
            echo "=== Deployment completed at $(date) ==="
          } 2>&1 | tee -a "$LOG_FILE"
          
          # Display result
          echo "Deployment completed. Log saved to $LOG_FILE"
        '